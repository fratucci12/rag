# Arquivo de Configuração Central para o Projeto RAG

# --- Configurações do Banco de Dados ---
database:
  # A DSN (Data Source Name) será lida da variável de ambiente PG_DSN
  docs_table: "documents"
  chunks_prefix: "chunks" # Ex: chunks_pages_800x120
  index_type: "ivfflat" # ou "hnsw"

# --- Configurações de Indexação (main.py) ---
indexing:
  manifest_path: "data/manifest.ndjson"
  # Limita o número de entradas do manifesto a serem processadas (0 = todas)
  limit_entries: 0
  # Se true, apaga os dados das tabelas de estratégia antes de inserir novos
  reset_strategies: false

# --- Configurações dos Modelos de Embedding ---
models:
  # Backend a ser usado: "local" ou "openai"
  default_backend: "openai"
  local:
    # Modelo da biblioteca sentence-transformers
    embedding_model: "sentence-transformers/all-MiniLM-L6-v2"
    # Dimensão do vetor do modelo acima
    embedding_dim: 384
  openai:
    embedding_model: "text-embedding-3-small"
    embedding_dim: 1536

# --- Configurações de Lotes (Batch API) ---
batch_processing:
  # Limite total de tokens por ficheiro de lote (JSONL)
  # Ajuste conforme a sua necessidade/cota. Padrão seguro: 2 milhões.
  token_limit_per_batch: 2000000
  # Intervalo entre checagens de status dos lotes ativos (segundos)
  poll_interval_seconds: 60
  # Espera entre a conclusão/criação de lotes para evitar enqueued limit (segundos)
  create_cooldown_seconds: 180
  # Backoff quando a API retorna erro de limite de lotes enfileirados (segundos)
  enqueued_retry_backoff_seconds: 180

# --- Estratégias de Chunking ---
# Defina aqui as estratégias que serão aplicadas durante a indexação.
# O nome (ex: 'pages_800x120') será usado para criar a tabela no banco.
strategies:
  pages_1500x400:
    kind: "pages"
    max_tokens: 1500
    overlap: 400
    use_tiktoken: true
  paras_1500x400:
    kind: "paras"
    max_tokens: 1500
    overlap: 400
    use_tiktoken: true
  rec_2000x400:
    kind: "rec"
    max_tokens: 2000
    overlap: 400
    use_tiktoken: true

# --- Configurações do Testador de Recuperação (retrieval_tester.py) ---
retrieval_testing:
  # Arquivo com as perguntas para o modo batch
  query_file: "tests/queries.json"
  # Arquivo de saída para os resultados do modo batch
  output_file: "tests/test_results.jsonl"
  # Quantos resultados de topo retornar por busca (default)
  top_k: 5
  # Ativa a avaliação com um LLM como juiz
  evaluate_with_llm: true
  # Modelo LLM a ser usado como juiz (requer chave da OpenAI)
  judge_model: "gpt-4o-mini"

  reranker_model: "cross-encoder/mmarco-mMiniLMv2-L12-H384-v1"
  # Threshold do juiz LLM para considerar um "hit" (exibe na tabela)
  judge_threshold: 4
  # Parâmetros padrão para retrieval (podem ser sobrescritos por estratégia)
  candidates: 25   # candidatos iniciais para re-ranking
  rrf_k: 60        # parâmetro K do RRF na busca híbrida
  # Configuração HyDE padrão (pode ser sobrescrita por estratégia)
  hyde:
    enabled: false
    model: "gpt-3.5-turbo"
  # Lista de métodos a executar; pode ser sobrescrita por estratégia
  methods:
    - "Similarity"
    - "Hybrid"
    - "Re-Ranking"
    - "Hybrid+Re-Ranking"
  # Overrides por estratégia (nome deve bater com a chave em 'strategies')
  per_strategy:
    # exemplo de override (descomente e ajuste conforme necessidade):
    # pages_1500x400:
    #   top_k: 8
    #   candidates: 30
    #   rrf_k: 80
    #   methods: ["Hybrid+Re-Ranking"]
    #   hyde:
    #     enabled: true
    #     model: "gpt-4o-mini"
  # Métodos de recuperação a executar (em ordem)
  methods:
    - "Similarity"
    - "Hybrid"
    - "Re-Ranking"
    - "Hybrid+Re-Ranking"
    - "HyDE"
  # Modelo para gerar texto hipotético no HyDE
  hyde_model: "gpt-3.5-turbo"
